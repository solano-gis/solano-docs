---
title: "sage-web"
description: "Chat UI and AI orchestration — where the intelligence lives"
---

**Repository:** `solano-gis/sage-web` | **Deployed to:** Vercel (private URL) | **Tech:** Next.js 15, AI SDK v6, multi-model (Claude, Gemini, GPT)

sage-web is the orchestration layer. It hosts the chat interface, manages AI conversations, connects to MCP servers, handles map screenshots, and enforces policy (authentication, disclaimers, rate limiting).

## What it does

1. **Chat interface** — React-based conversational UI with streaming responses
2. **AI orchestration** — Sends user messages + map context to Claude, manages multi-step tool chains
3. **MCP client** — Creates per-request HTTP connections to sage-gov and sage-gis
4. **Map bridge** — Communicates with sage-map iframe via postMessage for map commands and screenshots
5. **Token optimization** — Strips old screenshots, manages context window within 200K limit
6. **Policy layer** — System prompt, disclaimers, topic scoping, chain limits

## Request lifecycle

![sage-web request flow — Browser to /api/chat to Claude to response](/images/sage-web-request-flow.png)

## Dynamic tool loading

Instead of sending all 59 tool schemas (~16K tokens) on every request, tools are split into **core** (always available) and **groups** (loaded on demand):

**17 core tools** (~5K tokens) — always available:
- Property: `geocode_address`, `search_places`, `get_parcel_details`, `get_zoning`, `get_flood_zone`, `get_fire_hazard_zone`, `get_elevation`, `get_special_districts`, `get_supervisor_district`, `find_nearby`
- Maps: `show_map`, `update_map`, `locate_in_view`, `query_map_features`
- Reference: `get_layer_context`
- Imagery: `get_oblique_imagery`
- Meta: `load_tool_group`, `load_skill`

**11 on-demand groups** — loaded when Claude calls `load_tool_group()`:

| Group | Tools | Purpose |
|-------|-------|---------|
| `county_code` | 4 | Zoning code, subdivisions, code sections |
| `budget` | 6 | Department budgets, staffing, revenue |
| `general_plan` | 7 | Land use policies, housing, agriculture |
| `org_chart` | 6 | Departments, divisions, positions |
| `directions` | 2 | Driving directions, travel time |
| `gis_layers` | 6 | GIS data catalog, layer search, downloads |
| `geoprocessing` | 2 | Dissolve shapefiles, inspect layers |
| `meetings` | 5 | Board/committee agendas and minutes |
| `image_gen` | 2 | Infographics, image editing |
| `parcels` | 2 | Bulk parcel search, buffer/notification lists |
| `oblique` | 1 | Oblique aerial imagery |

This cuts schema overhead by ~50% while preserving full capability.

### Domain knowledge (skills)

Alongside tool groups, sage-web bundles **domain knowledge** from [sage-knowledge](/knowledge) — curated expertise across 10 skill areas. The AI discovers available skills via an `<available_knowledge>` XML block in the system prompt (~750 tokens), then loads specific skills on demand via `load_skill()`.

Skills complement tool groups: tool groups provide **tool schemas** (what tools are available), while skills provide **domain knowledge** (how to interpret results, what workflows to follow, what gotchas exist). See the [Knowledge Base](/knowledge) page for details.

## System prompt

The system prompt in `lib/prompts.ts` (~25K characters) governs SAGE's behavior:

- **Personality:** Friendly, concise, proactive with maps, honest about limits
- **Scope:** Solano County focus (7 cities + unincorporated), graceful off-topic redirects
- **Jurisdiction routing:** Automatic detection that mailing address ≠ legal jurisdiction
- **Response scaling:** Quick answers for simple lookups, deep dives for policy research
- **Tool chaining patterns:** Predefined workflows for common question types
- **Sensitive topics:** Language rules for fire zones, flood zones, zoning, property boundaries

The prompt is split into two parts for **prompt caching**: a static base (~4K tokens, cached 5 minutes) and dynamic map context (per-request). This saves ~90% on input token costs across multi-step chains.

## Token optimization

After 1-2 tool calls with map screenshots, context can approach the 200K limit. `optimizeTokenBudget()` runs before every AI call:

1. Strips base64 image blobs from old tool results (Claude has already analyzed them)
2. Keeps only the latest screenshot; removes older ones
3. Limits reasoning to 10 steps to prevent runaway chains

## Key files

| File | Purpose |
|------|---------|
| `app/api/chat/route.ts` | Main API handler — MCP connections, AI streaming, tool orchestration |
| `lib/prompts.ts` | System prompt — AI behavioral guide |
| `lib/tool-groups.ts` | Core tools + on-demand group definitions |
| `lib/skills.ts` | Domain knowledge loader (sage-knowledge integration) |
| `lib/mcp.ts` | Dual MCP client factory (sage-gov + sage-gis) |
| `lib/token-budget.ts` | Context window optimization |
| `lib/locate-in-view.ts` | Gemini Flash vision detection pipeline |
| `components/Chat.tsx` | Main chat UI component |
| `components/ToolResult.tsx` | Tool call rendering + client-side map commands |
| `hooks/useMapPostMessage.ts` | iframe communication, screenshot validation |
| `hooks/useMapPanel.ts` | Map panel state, command queue |
| `lib/interaction-store.ts` | Interaction logging — Blob persistence, list/get/purge |
| `lib/server-logger.ts` | `prodLog()` — structured JSON events to console + collector |
| `app/api/logs/route.ts` | Authenticated REST endpoint for querying interaction logs |
| `scripts/sage-logs.sh` | CLI tool for querying production interaction logs |

## Tool execution model

Tools execute in three different places:

| Type | Where it runs | Examples |
|------|---------------|----------|
| **MCP tools** | sage-gov or sage-gis (Vercel backend) | `get_parcel_details`, `get_zoning`, `search_county_code` |
| **Local tools** | sage-web API route (server-side) | `load_tool_group`, `load_skill`, `query_map_features`, `locate_in_view` |
| **Client-side tool** | User's browser via iframe postMessage | `update_map` |

### update_map (client-side)

`update_map` is the AI's handle on the user's live map. It has no server execute — `ToolResult.tsx` intercepts it client-side and translates it into postMessage commands to the sage-map iframe.

**Parameters:**

| Parameter | Type | Effect |
|-----------|------|--------|
| `center` | `{ latitude, longitude }` | Navigate to coordinates |
| `zoom` | `number` | Set zoom level |
| `pan` | `string` | Relative pan direction (north, southeast, etc.) |
| `pan_amount` | `number` | Pan distance as % of viewport (default 50) |
| `layers` | `[{ title, visible }]` | Toggle layer visibility |
| `highlight_apns` | `string[]` | Highlight parcels by APN |
| `highlight_features` | `{ layer_title, where, max_features? }` | Highlight features by SQL WHERE expression |
| `clear_highlights` | `boolean` | Remove all highlights |
| `add_overlay` | `{ url, title, layerType, opacity }` | Add external service layer |
| `remove_overlay` | `string` | Remove an overlay by title |

**Feature highlighting** queries any FeatureServer layer by SQL WHERE expression. The AI constructs expressions from domain knowledge — e.g., `highlight_features: { layer_title: "FHSZ", where: "HAZ_CLASS = 'Very High'" }`. sage-web resolves layer titles to URLs via its layer registry (`lib/layer-registry.ts`) before sending the command.

### Ack-before-output

`update_map` waits up to 8 seconds for the iframe's `command-ack` before calling `addToolOutput`. The tool output includes an `ackStatus` field (`confirmed`, `unconfirmed`, or `failed`) so the AI knows whether it can trust the map state. This prevents hallucinated map descriptions when the iframe bridge is broken. See [Map Protocol](/integration/map-protocol) for details.

### Highlight metadata in tool output

For `highlight_features` calls, the tool output includes metadata from the ack:

```json
{
  "message": "Highlighted and zoomed to Parcels where valtv > 200000 (234 features)",
  "ackStatus": "confirmed",
  "featureCount": 234,
  "exceededLimit": false,
  "fieldNames": ["OBJECTID", "parcelid", "Acres", "valland", "valimps", "valtv", "usecdesc"],
  "layerTitle": "Parcels",
  "where": "valtv > 200000"
}
```

This gives the AI the breadcrumbs to run follow-up queries on the same selection using `query_map_features` — e.g., `stats` mode for value distributions or `sample` mode for top-N lists — without auto-sending attribute data that could swamp the context window. The AI decides whether a follow-up is worth the tokens based on the user's question.
